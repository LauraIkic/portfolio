[
  {
    "title": "Massive Art Fullstack Developer",
    "name": "massiveArt",
    "image": "",
    "thumbnail": "/massiveArt.png",
    "description": "JUL 2019 - CURRENT",
    "icon": "",
    "text": "The \"City Guide\" project is an innovative combination of machine learning and augmented reality (AR) that aims to enhance the travel experience. The project is divided into two main components: an image recognition system and an AR experience, with a primary focus on the latter.\n\nImage Recognition Component\n\nThe first component of the project involves capturing images through a camera and analyzing them with the help of a Vision API. This API is designed to detect landmarks within the captured image and return relevant information. The results are cross-referenced with a database that holds additional details about each landmark, allowing for further exploration. Additionally, the coordinates of the nearest landmark are calculated, helping the system understand the user’s exact location.\n\nAugmented Reality Experience\n\nOnce the image recognition system has detected a landmark, the project activates an AR session. Using the coordinates of the landmark, a virtual 3D object is positioned in the user's environment, displaying the name of the landmark. Users can interact with the object by tapping on it, which brings up a detailed view of the landmark, offering additional information.\n\nThe second prototype of the project, developed in Kotlin, improved upon the initial version, which was built with Flutter. The new version introduced features like a comprehensive landmark overview. Users can filter landmarks by city or category, easily searching for points of interest. Each landmark also provides more detailed information, enriching the user’s experience. Another notable addition is the route generation feature, which uses Google Maps to create optimal travel routes between selected landmarks, saving users time when planning their visits.\n\nUser-Friendly Interface with Jetpack Compose\n\nThe app’s user interface (UI) was enhanced with Jetpack Compose, a modern UI toolkit for Android development. This upgrade significantly improved the app's design, surpassing the limitations of traditional XML-based UI frameworks. Upon starting the app, users are greeted with two buttons: one for initiating the scanning process and another for accessing the landmark overview. The scanning process lets users capture an image of a landmark, while the overview offers a searchable list of landmarks, with filtering options based on city or category.\n\nThe landmark data is stored in Firebase, a NoSQL database that supports fast, real-time data retrieval, and was integrated during the machine learning phase of the project.\n\nConclusion\n\nThe \"City Guide\" project merges cutting-edge machine learning and AR technologies to offer travelers an immersive and interactive way to explore landmarks. By combining image recognition with AR, users can quickly identify landmarks and access detailed information, all while navigating with ease through optimized routes. This project has the potential to revolutionize the way we explore cities, making it an essential tool for modern-day travelers.",
    "tools": ["PHP", "Symfony", "TypeScript", "React.js"],
    "imageGallery": [
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore.png"
      },
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore-1.png"
      }
    ],
    "links": [
    ]
  },
  {
    "title": "Elements (Valantic) - Full Stack Developer",
    "name": "elements",
    "image": "",
    "thumbnail": "/elements.png",
    "description": "APR 2022 - AUG 2022 Developed and maintained responsive and user‑friendly web applications for clients across various industries.\n• Implemented back‑end solutions using technologies including PHP to handle server‑side logic and database interactions.\n• Successfully implemented and leveraged Pimcore CMS in various client projects within the digital agency.",
    "icon": "",
    "text": "The \"City Guide\" project is an innovative combination of machine learning and augmented reality (AR) that aims to enhance the travel experience. The project is divided into two main components: an image recognition system and an AR experience, with a primary focus on the latter.\n\nImage Recognition Component\n\nThe first component of the project involves capturing images through a camera and analyzing them with the help of a Vision API. This API is designed to detect landmarks within the captured image and return relevant information. The results are cross-referenced with a database that holds additional details about each landmark, allowing for further exploration. Additionally, the coordinates of the nearest landmark are calculated, helping the system understand the user’s exact location.\n\nAugmented Reality Experience\n\nOnce the image recognition system has detected a landmark, the project activates an AR session. Using the coordinates of the landmark, a virtual 3D object is positioned in the user's environment, displaying the name of the landmark. Users can interact with the object by tapping on it, which brings up a detailed view of the landmark, offering additional information.\n\nThe second prototype of the project, developed in Kotlin, improved upon the initial version, which was built with Flutter. The new version introduced features like a comprehensive landmark overview. Users can filter landmarks by city or category, easily searching for points of interest. Each landmark also provides more detailed information, enriching the user’s experience. Another notable addition is the route generation feature, which uses Google Maps to create optimal travel routes between selected landmarks, saving users time when planning their visits.\n\nUser-Friendly Interface with Jetpack Compose\n\nThe app’s user interface (UI) was enhanced with Jetpack Compose, a modern UI toolkit for Android development. This upgrade significantly improved the app's design, surpassing the limitations of traditional XML-based UI frameworks. Upon starting the app, users are greeted with two buttons: one for initiating the scanning process and another for accessing the landmark overview. The scanning process lets users capture an image of a landmark, while the overview offers a searchable list of landmarks, with filtering options based on city or category.\n\nThe landmark data is stored in Firebase, a NoSQL database that supports fast, real-time data retrieval, and was integrated during the machine learning phase of the project.\n\nConclusion\n\nThe \"City Guide\" project merges cutting-edge machine learning and AR technologies to offer travelers an immersive and interactive way to explore landmarks. By combining image recognition with AR, users can quickly identify landmarks and access detailed information, all while navigating with ease through optimized routes. This project has the potential to revolutionize the way we explore cities, making it an essential tool for modern-day travelers.",
    "tools": ["PHP", "Symfony", "TypeScript", "React.js"],
    "imageGallery": [
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore.png"
      },
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore-1.png"
      }
    ],
    "links": [
    ]
  },
  {
    "title": "Grand Garage - Frontend Developer",
    "name": "grandGarage",
    "image": "",
    "thumbnail": "/grandGarage.png",
    "description": "JUL 2019 - MAR 2022 • Planned, designed and developed new front‑end features.\n• Started the website relaunch and set up the project’s architecture as well as the content management system (Storyblok).\n• Supported a new front‑end trainee and mentored her.",
    "icon": "",
    "text": "The \"City Guide\" project is an innovative combination of machine learning and augmented reality (AR) that aims to enhance the travel experience. The project is divided into two main components: an image recognition system and an AR experience, with a primary focus on the latter.\n\nImage Recognition Component\n\nThe first component of the project involves capturing images through a camera and analyzing them with the help of a Vision API. This API is designed to detect landmarks within the captured image and return relevant information. The results are cross-referenced with a database that holds additional details about each landmark, allowing for further exploration. Additionally, the coordinates of the nearest landmark are calculated, helping the system understand the user’s exact location.\n\nAugmented Reality Experience\n\nOnce the image recognition system has detected a landmark, the project activates an AR session. Using the coordinates of the landmark, a virtual 3D object is positioned in the user's environment, displaying the name of the landmark. Users can interact with the object by tapping on it, which brings up a detailed view of the landmark, offering additional information.\n\nThe second prototype of the project, developed in Kotlin, improved upon the initial version, which was built with Flutter. The new version introduced features like a comprehensive landmark overview. Users can filter landmarks by city or category, easily searching for points of interest. Each landmark also provides more detailed information, enriching the user’s experience. Another notable addition is the route generation feature, which uses Google Maps to create optimal travel routes between selected landmarks, saving users time when planning their visits.\n\nUser-Friendly Interface with Jetpack Compose\n\nThe app’s user interface (UI) was enhanced with Jetpack Compose, a modern UI toolkit for Android development. This upgrade significantly improved the app's design, surpassing the limitations of traditional XML-based UI frameworks. Upon starting the app, users are greeted with two buttons: one for initiating the scanning process and another for accessing the landmark overview. The scanning process lets users capture an image of a landmark, while the overview offers a searchable list of landmarks, with filtering options based on city or category.\n\nThe landmark data is stored in Firebase, a NoSQL database that supports fast, real-time data retrieval, and was integrated during the machine learning phase of the project.\n\nConclusion\n\nThe \"City Guide\" project merges cutting-edge machine learning and AR technologies to offer travelers an immersive and interactive way to explore landmarks. By combining image recognition with AR, users can quickly identify landmarks and access detailed information, all while navigating with ease through optimized routes. This project has the potential to revolutionize the way we explore cities, making it an essential tool for modern-day travelers.",
    "tools": ["JavaScript", "Vue.js", "Nuxt.js", "Storyblok"],
    "imageGallery": [
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore.png"
      },
      {
        "tile": "maker space image 1",
        "src": "/arCore/arCore-1.png"
      }
    ],
    "links": [
    ]
  }
]
